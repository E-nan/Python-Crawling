{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 기사 크롤링\n",
    "### 원하는 년/월/일을 입력받아 해당 기간에 원하는 단어가 들어간 기사제목을 추출 및 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import os   #환경 변수나 디렉터리, 파일 등의 OS 자원을 제어할 수 있게 해주는 모듈\n",
    "import sys #파이썬 파일을 실행할 때, 자기 자신의 파일명이 들어간다\n",
    "import datetime #날짜관련 모듈\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 네이버 뉴스 고정 url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 월마다 끝 날짜가 다르기 때문에 설정해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DateNum(year, mon):\n",
    "    mon = int(mon)\n",
    "\n",
    "    if mon % 2 != 0 and mon < 8 or mon % 2 == 0 and mon > 7:\n",
    "        return 31\n",
    "    elif mon == 2:           # 2월의 날짜는 혼자다름\n",
    "        if int(year)%4 == 0: #윤년이면 29\n",
    "            return 29\n",
    "        else:                #윤년이면 28\n",
    "            return 28\n",
    "    elif mon % 2 == 0 and mon < 7 or mon % 2 != 0 and mon > 8:\n",
    "        return 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "년도와 월을 입력받아서 끝날짜가 다른 월을 구분하고 해당하는 월의 일을 반환한다.<br>\n",
    "2월은 윤년인지 평년인지 구분한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 페이지 응답 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_res(url):\n",
    "    request = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    #print(rescode)\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        xmlsoup = BeautifulSoup(response_body,'html.parser')\n",
    "        return xmlsoup\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 단어를 찾는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_word(wordlist, nword):\n",
    "    rst = re.search(nword,wordlist)\n",
    "    if(rst == None) :\n",
    "        return 0\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Article_Post(link):\n",
    "    request = urllib.request.Request(link)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    response_body = response.read()\n",
    "    a_html = BeautifulSoup(response_body,'html.parser')\n",
    "    try :\n",
    "        article_org = a_html.find('div',{'id':'articleBodyContents'}).get_text(strip=True)\n",
    "        article = Remove_Character(article_org)\n",
    "    except :\n",
    "        print(\"기사 없음\")\n",
    "        return 0\n",
    "    #print(article)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_Character(wordlist):\n",
    "    wordlist = re.sub('<b>','',wordlist,0)\n",
    "    wordlist = re.sub(\"</b>\",'',wordlist,0)\n",
    "    wordlist = re.sub('&quot;','',wordlist,0) \n",
    "    wordlist = re.sub('&apos;','',wordlist,0)\n",
    "    wordlist = re.sub('&lt;','',wordlist,0)\n",
    "    wordlist = re.sub('&gt;','',wordlist,0)\n",
    "    wordlist = re.sub(\"// flash 오류를 우회하기 위한 함수 추가\",'',wordlist,0)\n",
    "    wordlist = re.sub(\"function _flash_removeCallback\",'',wordlist,0)\n",
    "    wordlist = re.sub(\"\\(\\)\",'',wordlist,0)\n",
    "    wordlist = re.sub(\"\\{\\}\",'',wordlist,0)\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 년도와 월을 입력받아 해당 기간의 모든 기사를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newspage(year, mon, nword):\n",
    "    if mon < 10:  # 월이 10 이하일 경우 앞에 0 추가\n",
    "        Adate = '0' + str(mon)\n",
    "    else:\n",
    "        Adate = str(mon)\n",
    "\n",
    "    days = DateNum(year, mon)  # 각 월에 해당하는 날짜 추출\n",
    "    for days in range(1, days+1, 1):\n",
    "        if days < 10:  # 날짜가 10 이하일경우 앞에 0 추가\n",
    "            Bdate = '0' + str(days)\n",
    "        else:  # 그외 날짜는 그대로 저장\n",
    "            Bdate = str(days)\n",
    "        date = year + str(Adate) + str(Bdate)\n",
    "        url_date = url + '&date=' + date\n",
    "        print(url_date)\n",
    "\n",
    "        try:\n",
    "            xmlsoup = url_res(url_date)\n",
    "            pagePart = xmlsoup.find('div', {'class': 'paging'})\n",
    "            anchorNumber = pagePart.find_all({'a': 'href'})\n",
    "            pageNumber = len(anchorNumber) + 1\n",
    "\n",
    "            if (pageNumber == 11):\n",
    "                imsiUrl = url_date + '&page=11'\n",
    "                xmlsoup = url_res(imsiUrl)\n",
    "                pagePart = xmlsoup.find('div', {'class': 'paging'})\n",
    "                anchorNumber = pagePart.find_all({'a': 'href'})\n",
    "                pageNumber = len(anchorNumber) + 10\n",
    "            print(\"페이지수\", pageNumber)\n",
    "\n",
    "            for page in range(1, pageNumber + 1, 1):  # 해당 날의 모든 페이지 링크를 추출\n",
    "                newDayUrl = url_date + '&page=' + str(page)\n",
    "                # print(newDayUrl) #각 페이지별 링크\n",
    "                # print(page)      #page번째 페이지\n",
    "                xmlsoup = url_res(newDayUrl)\n",
    "                listBody = xmlsoup.find('div',{'class':'list_body'})\n",
    "                allList = listBody.findAll('li')\n",
    "                for alist in allList:\n",
    "                    Title = alist.find('a').text\n",
    "                    result = find_word(Title, nword)\n",
    "                    if(result ==1 ):   #찾고자 하는 단어가 있다면\n",
    "                        print(Title)   #기사제목\n",
    "                        Link = alist.find('a')['href']\n",
    "                        Article = Article_Post(Link)\n",
    "                        if(Article==0):\n",
    "                            continue\n",
    "                        Author = alist.find('span',{'class':'writing'}).text # 신문사\n",
    "                        nDate = alist.find('span',{'class':'date'}).text  #날짜\n",
    "                        wr.writerow([Author,nDate,Title,Article])\n",
    "                    else:\n",
    "                        continue\n",
    "            print('..........')\n",
    "\n",
    "        except:\n",
    "            print(\"페이지 응답 오류 발생\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.먼저 링크형식에 맞게 입력받은 월에 따라서 값을 설정해주고<br>\n",
    "고정형식의 url에 for문을 이용해 날짜를 붙여준다.<br>\n",
    "\n",
    "2.매일마다 기사의 개수가 다르기 때문에 각 날짜별로 페이지 수를 구한다.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 메인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "년도 : 2019\n",
      "시작 월 : 2\n",
      "끝   월 : 2\n",
      "기사 제목에 들어간 단어 : 폴리텍\n",
      "2019년도 2월 부터 2월 까지의 기사 링크\n",
      "<< 2 월>>\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190201\n",
      "페이지수 3\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190202\n",
      "페이지수 1\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190203\n",
      "페이지수 1\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190204\n",
      "페이지수 1\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190205\n",
      "페이지수 1\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190206\n",
      "페이지수 2\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190207\n",
      "페이지수 4\n",
      "한국폴리텍VI대, '로고라이트' 불 밝혀\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190208\n",
      "페이지수 5\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190209\n",
      "페이지수 1\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190210\n",
      "페이지수 2\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190211\n",
      "페이지수 5\n",
      "㈜퀴즈톡, 한국폴리텍대학 서울강서캠퍼스와 MOU 체결\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190212\n",
      "페이지수 6\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190213\n",
      "페이지수 5\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190214\n",
      "페이지수 4\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190215\n",
      "페이지수 4\n",
      "한국폴리텍대학 대전  학위수여식 \n",
      "한국폴리텍 양대웅 이사 대전캠퍼스 방문 \n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190216\n",
      "페이지수 1\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190217\n",
      "페이지수 2\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190218\n",
      "페이지수 7\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190219\n",
      "페이지수 7\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190220\n",
      "페이지수 9\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190221\n",
      "페이지수 8\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190222\n",
      "페이지수 5\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190223\n",
      "페이지수 2\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190224\n",
      "페이지수 2\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190225\n",
      "페이지수 9\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190226\n",
      "페이지수 8\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190227\n",
      "페이지수 7\n",
      "..........\n",
      "https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&listType=title&date=20190228\n",
      "페이지수 7\n",
      "한국폴리텍 대전 신입생 입학식\n",
      "..........\n"
     ]
    }
   ],
   "source": [
    "#현재 모듈의 이름을 담고 있는 내장변수\n",
    "#직접 실행하면 if문 실행되지만 다른 프로그램에서 import하면 if문 실행x\n",
    "if __name__ == '__main__':\n",
    "    year = input(\"년도 : \")\n",
    "    Amon = input(\"시작 월 : \")\n",
    "    Bmon = input(\"끝   월 : \")\n",
    "    nword = input(\"기사 제목에 들어간 단어 : \")\n",
    "\n",
    "    fname = year + Amon + Bmon\n",
    "    filename = 'Naver_' + fname + '.csv'\n",
    "    f = open(filename, 'w', encoding='utf-8', newline='')\n",
    "    wr = csv.writer(f)\n",
    "\n",
    "    if Amon > Bmon:\n",
    "        print(\"오류 : 시작 월은 끝 월보다 작아야 합니다.\")\n",
    "    else:\n",
    "        print(year + \"년도 \" + Amon + \"월 부터 \" + Bmon + \"월 까지의 기사 링크\")\n",
    "        for mon in range(int(Amon), int(Bmon) + 1, 1):\n",
    "            print('<<', mon, '월>>')\n",
    "            newspage(year, mon, nword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "년도와 시작, 끝 월을 입력받고 시작 월이 끝나는 월보다 크면 실행시키지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
